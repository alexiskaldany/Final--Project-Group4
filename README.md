# dialogsum

authors:
#  - name: "@alexiskaldany"

Paper
https://docs.google.com/document/d/1Lx1EMlMHAwfDtLLiaYEw1n2GinRzF_VgMLQfimVE_G4/edit

## Setup

1. Create the virtual env and install the dependencies:
``` bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```
2. To train the model, use the following code (just run dialogsum.py):

```
nohup python3 /home/ubuntu/Final--Project-Group4/code/dialogsum.py &
```

nohup allows our scripts to keep running even if the ssh connection closes to our EC2

## Notes

- It takes roughly 70 minutes to run a complete epoch. 
- Currently the training loop saves the model after each epoch, so even if the EC2 is shut down we won't lose all of the progress.

### Statistical Output

- The evaluation loop and the test loop have the richest data, and includes the actual predicted summary generated by the model.
- The training loop only records rouge1 score and loss for each step.
- Averages are calculated for the evalution and test loops and saved to a csv as well 


## Models Used

- Standard Parameters
```
MAX_LENGTH = 512
EPOCHS = 10
BATCH_SIZE = 8
learning_rate=3e-5,
weight_decay=0.01,
adam_beta1=0.9,
adam_beta2=0.98,
adam_epsilon=1e-6,
lr_scheduler_type="linear"
```


### "t5-small"


- 10 epochs
- rouge1: 0.5937

### "blenderbot_small-90M"

